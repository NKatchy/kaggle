{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Student Test Scores - Basic EDA\nThis is an EDA notebook for Kaggle's playground January 2026 competition, \"Predicting Student Test Scores\". This basic EDA is the first EDA I perform in every tabular data competition. It shows:\n* is column Categorical or Numeric\n* how many unique values per column\n* how many nan values per column\n* distribution of column values\n* relationship between column and target\n\nDiscussion about this notebook is [here][1]\n\n[1]: https://www.kaggle.com/competitions/playground-series-s6e1/discussion/665965","metadata":{}},{"cell_type":"markdown","source":"# Load Train Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s6e1/train.csv\")\nprint(f\"Train shape: {train.shape}\")\ntrain.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:10:29.57839Z","iopub.execute_input":"2026-01-04T17:10:29.578653Z","iopub.status.idle":"2026-01-04T17:10:33.032632Z","shell.execute_reply.started":"2026-01-04T17:10:29.578623Z","shell.execute_reply":"2026-01-04T17:10:33.031757Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Basic EDA Function\nThe following function was written by ChatGPT 5.2. It plots the relationship between features and target. And it plots the distrubtion of feature values. These insights can help us build models.","metadata":{}},{"cell_type":"code","source":"def plot_features_dual_axis(\n    df: pd.DataFrame,\n    cols: list[str],\n    target_col: str,\n    n_bins: int = 10,\n    n_wide: int = 3,\n    figsize_per_plot: tuple[float, float] = (5, 4),\n    int_as_cat_unique_max: int | None = 20,\n    cat_order: dict[str, list] | None = None,   # <-- NEW\n):\n    BAR_COLOR = \"tab:blue\"\n    LINE_COLOR = \"tab:orange\"\n\n    def is_categorical(s: pd.Series) -> bool:\n        return s.dtype == \"object\" or pd.api.types.is_string_dtype(s)\n\n    n_cols = len(cols)\n    n_rows = int(np.ceil(n_cols / n_wide))\n\n    fig, axes = plt.subplots(\n        n_rows,\n        n_wide,\n        figsize=(figsize_per_plot[0] * n_wide, figsize_per_plot[1] * n_rows),\n    )\n\n    axes = np.atleast_1d(axes).ravel()\n\n    for i, col in enumerate(cols):\n        ax1 = axes[i]\n        col_safe = col.replace(\"_\", r\"\\_\")\n\n        n_nan = df[col].isna().sum()\n        n_unique = df[col].nunique(dropna=True)\n\n        tmp = df[[col, target_col]].dropna()\n        if tmp.empty:\n            ax1.set_title(\n                rf\"$\\bf{{{col_safe}}}$\"\n                f\"\\n(empty after dropna; {n_unique} unique, {n_nan} nan)\"\n            )\n            continue\n\n        x = tmp[col]\n        y = tmp[target_col]\n\n        # ---------- TRUE CATEGORICAL ----------\n        if is_categorical(x):\n            type_str = \"categorical\"\n\n            # base counts / means\n            counts = x.value_counts()\n            mean_y = tmp.groupby(col)[target_col].mean()\n\n            # ---- APPLY USER-DEFINED CATEGORY ORDER (if provided) ----\n            if cat_order is not None and col in cat_order:\n                desired = list(cat_order[col])\n\n                # keep only categories present in data\n                ordered = [c for c in desired if c in counts.index]\n\n                # append any remaining categories not specified by user\n                remaining = [c for c in counts.index if c not in ordered]\n                final_order = ordered + remaining\n            else:\n                final_order = sorted(counts.index)\n\n            counts = counts.loc[final_order]\n            mean_y = mean_y.loc[final_order]\n\n            xpos = np.arange(len(final_order))\n\n            ax1.bar(xpos, counts.values, alpha=0.6, color=BAR_COLOR)\n            ax1.set_xlabel(col)\n            ax1.set_ylabel(\"Count\", color=BAR_COLOR)\n            ax1.tick_params(axis=\"y\", colors=BAR_COLOR)\n\n            ax1.set_xticks(xpos)\n            ax1.set_xticklabels(final_order, rotation=45, ha=\"right\")\n\n            ax2 = ax1.twinx()\n            ax2.plot(xpos, mean_y.values, marker=\"o\", color=LINE_COLOR)\n            ax2.set_ylabel(f\"Mean {target_col}\", color=LINE_COLOR)\n            ax2.tick_params(axis=\"y\", colors=LINE_COLOR)\n\n            ax1.set_title(\n                rf\"$\\bf{{{col_safe}}}$: Count vs Mean {target_col}\"\n                f\"\\n({type_str} with {n_unique} unique and {n_nan} nan)\"\n            )\n\n        # ---------- NUMERIC ----------\n        else:\n            type_str = \"numeric\"\n\n            xvals = x.values\n            yvals = y.values\n\n            mask = np.isfinite(xvals) & np.isfinite(yvals)\n            xvals = xvals[mask]\n            yvals = yvals[mask]\n\n            if len(xvals) == 0:\n                ax1.set_title(\n                    rf\"$\\bf{{{col_safe}}}$\"\n                    f\"\\n({type_str} with {n_unique} unique and {n_nan} nan)\"\n                )\n                continue\n\n            unique_vals = np.sort(np.unique(xvals))\n            n_unique_eff = len(unique_vals)\n\n            # --- Case 1: int-as-categorical ---\n            if int_as_cat_unique_max is not None and n_unique_eff <= int_as_cat_unique_max:\n                counts = np.array([(xvals == v).sum() for v in unique_vals])\n                mean_y = np.array([yvals[xvals == v].mean() for v in unique_vals])\n\n                xpos = np.arange(n_unique_eff)\n\n                ax1.bar(xpos, counts, alpha=0.6, color=BAR_COLOR)\n                ax1.set_xlabel(col)\n                ax1.set_ylabel(\"Count\", color=BAR_COLOR)\n                ax1.tick_params(axis=\"y\", colors=BAR_COLOR)\n\n                rotate = 45 if n_unique_eff > n_bins else 0\n                step = max(int(np.ceil(n_unique_eff / n_bins)), 1)\n                tick_idx = np.arange(0, n_unique_eff, step)\n\n                if pd.api.types.is_integer_dtype(x):\n                    tick_labels = unique_vals[tick_idx].astype(int)\n                else:\n                    tick_labels = unique_vals[tick_idx]\n\n                ax1.set_xticks(tick_idx)\n                ax1.set_xticklabels(\n                    tick_labels,\n                    rotation=rotate,\n                    ha=\"right\" if rotate else \"center\",\n                )\n\n                ax2 = ax1.twinx()\n                ax2.plot(xpos, mean_y, marker=\"o\", color=LINE_COLOR)\n                ax2.set_ylabel(f\"Mean {target_col}\", color=LINE_COLOR)\n                ax2.tick_params(axis=\"y\", colors=LINE_COLOR)\n\n                ax1.set_title(\n                    rf\"$\\bf{{{col_safe}}}$: Per-Value Count vs Mean {target_col}\"\n                    f\"\\n({type_str} with {n_unique} unique and {n_nan} nan)\"\n                )\n\n            # --- Case 2: low-cardinality numeric bins ---\n            elif n_unique_eff < n_bins:\n                counts = np.array([(xvals == v).sum() for v in unique_vals])\n                mean_y = np.array([yvals[xvals == v].mean() for v in unique_vals])\n\n                width = 0.8 * (np.min(np.diff(unique_vals)) if n_unique_eff > 1 else 1.0)\n\n                ax1.bar(unique_vals, counts, width=width, alpha=0.6, color=BAR_COLOR)\n                ax1.set_xlabel(col)\n                ax1.set_ylabel(\"Count\", color=BAR_COLOR)\n                ax1.tick_params(axis=\"y\", colors=BAR_COLOR)\n\n                ax2 = ax1.twinx()\n                ax2.plot(unique_vals, mean_y, marker=\"o\", color=LINE_COLOR)\n                ax2.set_ylabel(f\"Mean {target_col}\", color=LINE_COLOR)\n                ax2.tick_params(axis=\"y\", colors=LINE_COLOR)\n\n                ax1.set_title(\n                    rf\"$\\bf{{{col_safe}}}$: Per-Value Count vs Mean {target_col}\"\n                    f\"\\n({type_str} with {n_unique} unique and {n_nan} nan)\"\n                )\n\n            # --- Case 3: regular histogram ---\n            else:\n                bins = np.linspace(xvals.min(), xvals.max(), n_bins + 1)\n                bin_centers = 0.5 * (bins[:-1] + bins[1:])\n\n                counts, _ = np.histogram(xvals, bins=bins)\n                bin_idx = np.digitize(xvals, bins) - 1\n\n                mean_y = np.array([\n                    yvals[bin_idx == j].mean() if np.any(bin_idx == j) else np.nan\n                    for j in range(n_bins)\n                ])\n\n                ax1.bar(\n                    bin_centers,\n                    counts,\n                    width=(bins[1] - bins[0]),\n                    alpha=0.6,\n                    color=BAR_COLOR,\n                )\n                ax1.set_xlabel(col)\n                ax1.set_ylabel(\"Count\", color=BAR_COLOR)\n                ax1.tick_params(axis=\"y\", colors=BAR_COLOR)\n\n                ax2 = ax1.twinx()\n                ax2.plot(bin_centers, mean_y, marker=\"o\", color=LINE_COLOR)\n                ax2.set_ylabel(f\"Mean {target_col}\", color=LINE_COLOR)\n                ax2.tick_params(axis=\"y\", colors=LINE_COLOR)\n\n                ax1.set_title(\n                    rf\"$\\bf{{{col_safe}}}$: Histogram vs Mean {target_col}\"\n                    f\"\\n({type_str} with {n_unique} unique and {n_nan} nan)\"\n                )\n\n    for j in range(i + 1, len(axes)):\n        axes[j].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2026-01-04T17:12:24.723569Z","iopub.execute_input":"2026-01-04T17:12:24.724761Z","iopub.status.idle":"2026-01-04T17:12:24.827315Z","shell.execute_reply.started":"2026-01-04T17:12:24.724727Z","shell.execute_reply":"2026-01-04T17:12:24.826026Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display EDA","metadata":{}},{"cell_type":"code","source":"FEATURES = list( train.columns[1:-1] )\nprint(f\"There are {len(FEATURES)} features:\")\nprint(FEATURES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:23:15.760002Z","iopub.execute_input":"2026-01-04T17:23:15.760359Z","iopub.status.idle":"2026-01-04T17:23:15.76576Z","shell.execute_reply.started":"2026-01-04T17:23:15.760335Z","shell.execute_reply":"2026-01-04T17:23:15.764962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ordinal_order = {\n    \"sleep_quality\":[\"poor\",\"average\",\"good\"],\n    \"facility_rating\":[\"low\",\"medium\",\"high\"],\n    \"exam_difficulty\":[\"easy\",\"moderate\",\"hard\"],\n}\n\nplot_features_dual_axis(\n    train,\n    cols=FEATURES,\n    target_col=\"exam_score\",\n    n_bins=10,\n    n_wide=3,\n    int_as_cat_unique_max=20,\n    cat_order = ordinal_order,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:12:39.37251Z","iopub.execute_input":"2026-01-04T17:12:39.372848Z","iopub.status.idle":"2026-01-04T17:12:44.743033Z","shell.execute_reply.started":"2026-01-04T17:12:39.372825Z","shell.execute_reply":"2026-01-04T17:12:44.74203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusions\nFrom the above EDA we observe the following:\n* No columns have nan values\n* Age is low cardinality numeric which can be treated as categorical\n* Many categorical features have ordinal classes  \n* Many features have a nearly uniform linear distribution (i.e. columns don't have rare values with exception of internet access)\n* Many features have a linear relationship with target. Namely study_hours, class_attendance, sleep_hours, sleep_quality, facility_rating.\n* The other features seem to have a non linear relationship with target\n* All features appear to be predictive of target\n\nThe presence of strong linear relationships suggest building non linear models over the residuals of linear models. Next step EDA would be to explore interactions between features. How does one feature affect the relationship between another feature and target? The complexity of interactions can help us decide how to best use NN, GBDT, and stacking.","metadata":{}}]}