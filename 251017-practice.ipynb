{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#ライブラリをインポート\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sb\nimport lightgbm as lgb\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom ydata_profiling import ProfileReport","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#データを読み込む\npath =\"/kaggle/input/titanic/\"\ntrain = pd.read_csv(path + \"train.csv\")\ntest = pd.read_csv(path + \"test.csv\")\ndf = pd.concat([train , test])\ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Nameから敬称を抽出してカウントする\nTitles = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\ndf[\"Title\"] = Titles \n\ndf[\"Title\"].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#敬称をまとめる\ndf[\"Title\"] = df[\"Title\"].replace([\"Mlle\",\"Ms\"] ,\"Miss\")\ndf[\"Title\"] = df[\"Title\"].replace([\"Mme\",\"Lady\"] ,\"Mrs\")\ndf[\"Title\"] = df[\"Title\"].replace([\"Dona\" , \"Countess\" , \"Dr\",\"Rev\" , \"Don\" , \"Major\" , \"Col\" , \"Sir\" , \"Capt\" , \"Jonkheer\"] ,\"Rare\")\nprint(df[\"Title\"].value_counts())\nprint(df['Title'].info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#欠損値を埋める。Fareをとりあえず中央値で埋める。\ndf[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\nprint(df['Fare'].value_counts())\nprint(plt.hist(data=df , x=\"Fare\", bins=30))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#その後、対数変換して分布を整える\ndf['Fare_loge'] = np.log1p(df[\"Fare\"])\nprint(df['Fare_loge'].value_counts())\nprint(plt.hist(data=df , x=\"Fare_loge\", bins=30))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#AgeはTitleごとの中央値で埋める\ndf[\"Age\"] = df[\"Age\"].fillna(df.groupby(\"Title\")[\"Age\"].transform(\"median\"))\ndf.isnull().sum()\nprint(df[\"Age\"].value_counts())\nplt.hist(df[\"Age\"], bins=30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Embarkedは最頻値で埋める\n#最頻値が複数あるため[0]えｄ愛書の値を取り出す\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0]) \ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#特徴量エンジニアリング\n#EmbarkedとSexとTitleをワンホットエンコーディングする。\nemb = pd.get_dummies(df[\"Embarked\"],prefix=\"Emb\")\nsx = pd.get_dummies(df[\"Sex\"],prefix=\"Sex\")\nttl = pd.get_dummies(df[\"Title\"],prefix=\"Title\")\n\n#新しい特徴量として、Famsize,Isalone,IsFareZeroを追加する。\ndf[\"Famsize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\ndf[\"Isalone\"] = df[\"Famsize\"]==1\ndf[\"IsFareZero\"] = df[\"Fare\"]==0\n\n#追加した特徴量をデータフレームへ統合する。不要なカラムは削除する。\ndf2 = pd.concat([df, emb, sx, ttl],axis=1)\ndf3 = df2.drop(columns=[\"Fare\", \"Sex_male\", \"Embarked\", \"Sex\", \"Title\", \"Cabin\", \"Ticket\", \"Name\"])\n\ndf3.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#機械学習モデルに投入するデータを作成する。\ntrain_df = df3[~df3[\"Survived\"].isnull()]\ntest_df = df3[df3[\"Survived\"].isnull()]\n\ntrain_x = train_df.drop(columns=[\"Survived\"])\ntrain_y = train_df[\"Survived\"]\ntrain_y.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ↓ランダムフォレスト","metadata":{}},{"cell_type":"code","source":"# ランダムフォレストモデル（分類器）の定義\n# n_estimators: 使用する決定木の数（一般的に多いほど性能が向上するが、計算時間が増える）\n# max_depth: 決定木の深さの最大値（過学習を防ぐために設定することが多い）\nrf_model = RandomForestClassifier(\n    n_estimators=200,      # 適切な木の本数\n    max_depth=7,           # 深さを制限（過学習対策）\n    min_samples_split=10,  # 分岐の条件を厳しくする\n    min_samples_leaf=5,    # 葉のサイズを大きくする\n    random_state=42,\n    n_jobs=-1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **↓LithtGBM**","metadata":{}},{"cell_type":"code","source":"#機械学習モデルを呼び出し、学習を行う。\nlgb_model = lgb.LGBMClassifier(\n    objective='binary',\n    learning_rate=0.03,    # 低めに設定\n    n_estimators=150,      # 試行回数\n    num_leaves=8,          # 浅い木に制限（過学習対策）\n    max_depth=5,           # 深さの制限\n    random_state=42,\n)\nprint(\"LightGBMのハイパーパラメータを設定しました。\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#↓どちらのモデルで学習するか、選んでネ！\n#rf_model.fit(train_x , train_y)\nlgb_model.fit(train_x , train_y)\n\nprint(\"学習が完了しました\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#交差検証を開始する。5分割がよさそう。\nN_SPLITS = 5\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\n# cross_val_scoreで精度（accuracy）を計算\n# scoring='accuracy' はタイタニックの評価指標\naccuracy_scores = cross_val_score(\n    estimator=lgb_model, \n    X=train_x, \n    y=train_y, \n    cv=skf, \n    scoring='accuracy',\n    n_jobs=-1 # 全てのコアを使って並列処理（高速化）\n)\n\n# 結果の表示\nprint(f\"各分割での精度スコア ({N_SPLITS}-Fold): {accuracy_scores}\")\nprint(f\"----------------------------------------\")\nprint(f\"平均精度 (Mean Accuracy): {accuracy_scores.mean():.4f}\")\nprint(f\"スコアの標準偏差 (Std Dev): {accuracy_scores.std():.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#予測用データの作成をする\ntest_x = test_df.drop(columns=[\"Survived\"])\ntest_y = test_df[\"Survived\"]\nprint(\"予測用データの作成が完了しました\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#学習したパラメータをテストデータへ適用して予測する。\ntest_y = lgb_model.predict(test_x)\n\n#提出用のデータを作る。\nsubmission_df = pd.DataFrame({\n    \"PassengerId\" : test_df[\"PassengerId\"],\n    \"Survived\" : test_y.astype(int)\n})\n\n#csvで書き出す\nsubmission_df.to_csv(\"first_submission13_IsFareZero_farelog_Emb.csv\" , index=False)\nprint(\"書き出しが完了しました\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# プロファイルレポートの生成\nprofile = ProfileReport(train_df, title='My Data Profiling Report')\n# HTMLファイルとして保存\nprofile.to_file(\"my_report.html\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"farezero =train_df[train_df[\"Fare\"]==0]\nfarezero","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"次：\n①ランダムフォレストに変えてみる→LithtGBMよりスコアが伸びなそう。\nハイパーパラメータチューニングを頑張ってみる。→結構よい感じになってきた。\n\n②Fare=0の乗客がかなりいる。調べてみると、ほぼ生き残っていないので、新しい特徴量（IsFareZero）を作ってみる。→スコア変わらず。\n\n③Fareの最大値が大きいため、対数変換をして新しい特徴量として加える→スコア変わらず\n\n④Embarkedを特徴量に追加。→そのままではスコアが下がった。→num_leavesとdepthを2ずつ増やしてみた→めっちゃ下がったからもどした","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}